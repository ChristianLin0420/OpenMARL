defaults:
  - _self_
  - task: default_task

name: openvla_${task.name}
_target_: openvla_policy.workspace.openvla_workspace.OpenVLAWorkspace

task_name: ${task.name}
exp_name: "openvla"
agent_id: 0  # Override via command line: agent_id=0, agent_id=1, etc.

# Model configuration
model:
  model_name: "openvla/openvla-7b"
  use_lora: True
  lora_rank: 32
  lora_alpha: 64
  lora_dropout: 0.0
  torch_dtype: "bfloat16"
  image_size: 224
  action_dim: 8

# Training configuration
training:
  device: "cuda:0"
  seed: 42
  num_epochs: 50
  learning_rate: 5.0e-4
  min_learning_rate: 1.0e-6
  weight_decay: 1.0e-6
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_eps: 1.0e-8
  max_grad_norm: 1.0
  gradient_accumulate_every: 1
  use_scheduler: True
  
  # Image augmentation
  image_aug: True
  augment_crop_ratio: 0.9
  
  # Validation
  val_split: 0.1
  val_every: 5                        # Validate every 5 epochs
  
  # Checkpointing
  checkpoint_every: 10                # Checkpoint every 10 epochs
  resume: False
  
  # Early stopping
  early_stopping: True
  early_stopping_patience: 20         # Wait 20 epochs before stopping
  early_stopping_min_delta: 1e-7
  
  # Simulation evaluation
  eval_in_sim: True
  eval_sim_every_n_epochs: 10         # Run sim eval every 10 epochs
  eval_sim_episodes: 4               # More episodes for reliable metrics
  eval_sim_num_envs: 4
  eval_sim_max_steps: 200             # Longer episodes
  
  # Debug mode (disabled for production)
  debug: False
  max_train_steps: null
  max_val_steps: null

# Dataloader configuration
dataloader:
  batch_size: 32
  num_workers: 8
  shuffle: True
  pin_memory: True

val_dataloader:
  batch_size: 32
  num_workers: 4
  shuffle: False
  pin_memory: True

# Logging configuration
logging:
  project: "openmarl"
  mode: "online"
  name: "${task_name}_${exp_name}_Agent${agent_id}"
  tags: ["${name}", "${task_name}", "${exp_name}", "Agent${agent_id}"]
  
  log_every_n_steps: 50               # Log less frequently
  log_gradients: True
  log_learning_rate: True

# Hydra configuration
hydra:
  job:
    override_dirname: ${name}
  run:
    dir: data/outputs/${now:%Y.%m.%d}/${now:%H.%M.%S}_${name}_${task_name}
  sweep:
    dir: data/outputs/${now:%Y.%m.%d}/${now:%H.%M.%S}_${name}_${task_name}
    subdir: ${hydra.job.num}

